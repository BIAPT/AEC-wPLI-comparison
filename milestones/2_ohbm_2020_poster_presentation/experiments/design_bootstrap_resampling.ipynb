{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yacine Mahdid June 12 2020\n",
    "The goal of this notebook is to load data from the 20 binary classifier that were made and generate the bootstrap confidence interval for them using the best classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-penality=l2_C=1.0 : 4\n",
      "lda-solver=svd : 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The input parameter should be constructed as such:\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "import config as cfg\n",
    "\n",
    "def load_pickle(filename):\n",
    "    '''Helper function to unpickle the pickled python obj'''\n",
    "    file = open(filename, 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def find_best_model(best_params):\n",
    "    \"\"\" helper fo find best model given the best parameter \"\"\"\n",
    "    \n",
    "    models_occurence = {}\n",
    "    for param in best_params:\n",
    "        \n",
    "        clf = param['clf']\n",
    "        if isinstance(clf, LogisticRegression):\n",
    "            penalty = param['clf__penalty']\n",
    "            c = param['clf__C']\n",
    "            key = f\"log-penality={penalty}_C={c}\"\n",
    "        elif isinstance(clf, LinearSVC):\n",
    "            c = param['clf__C']\n",
    "            key = f\"svc-kernel=linear_C= {c}\"\n",
    "        elif isinstance(clf, DecisionTreeClassifier):\n",
    "            criterion = param['clf__criterion']\n",
    "            key = f\"dec-criterion{criterion}\"\n",
    "        elif isinstance(clf, RandomForestClassifier):\n",
    "            n_estimators = param['clf__n_estimators']\n",
    "            max_depth = param['clf__max_depth']\n",
    "            min_samples_split = param['clf__min_samples_split']\n",
    "            min_samples_leaf = param['clf__min_samples_leaf']\n",
    "            key = f\"rand-n_estimators={n_estimators}-max_depth={max_depth}-min_samples_split={min_samples_split}-min_samples_leaf={min_samples_leaf}\"\n",
    "        elif isinstance(clf, LinearDiscriminantAnalysis):\n",
    "            solver = param['clf__solver']\n",
    "            key = f\"lda-solver={solver}\"\n",
    "        \n",
    "        if key not in models_occurence:\n",
    "            models_occurence[key] = 1\n",
    "        else:\n",
    "            models_occurence[key] = models_occurence[key] + 1\n",
    "            \n",
    "    for key, value in models_occurence.items():\n",
    "        print(f\"{key} : {value}\")\n",
    "\n",
    "    best_clf_params = max(models_occurence, key=models_occurence.get)\n",
    "\n",
    "    content = best_clf_params.split('-')\n",
    "    \n",
    "    if content[0] == \"log\":\n",
    "        C = content[1]\n",
    "        clf = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000, C=C)\n",
    "    elif content[0] == \"svc\":\n",
    "        C = content[1]\n",
    "        clf = LinearSVC(C=C)\n",
    "    elif content[0] == \"dec\":\n",
    "        criterion = content[1]\n",
    "        clf = DecisionTreeClassifier(criterion=criterion)\n",
    "    elif content[0] == \"rand\":\n",
    "        n_estimators = content[1]\n",
    "        max_depth = content[2]\n",
    "        min_samples_split = content[3]\n",
    "        min_samples_leaf = content[4]\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                                     min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "        key = f\"rand_n_estimators={n_estimators}_max_depth={max_depth}_min_samples_split={min_samples_split}_min_samples_leaf={min_samples_leaf}\"\n",
    "    elif content[0] == \"lda\":\n",
    "        content = content[1]\n",
    "        clf = LinearDiscriminantAnalysis(solver=solver)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# This will be given by the srun in the bash file\n",
    "arg = \"best_clf_pli_emf5_func-wei.pickle\"\n",
    "best_clf_filename =  f\"/home/yacine/Documents/BIAPT/testing/{arg}\"\n",
    "\n",
    "best_clf_data = load_pickle(best_clf_filename)\n",
    "clf = find_best_model(best_clf_data['best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
